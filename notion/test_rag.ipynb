{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -qU langchain pinecone-client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary modules\n",
    "from langchain.chains import RetrievalQAWithSourcesChain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from RAG import init_rag\n",
    "\n",
    "\n",
    "index_name = 'notion-db-chatbot'\n",
    "openai_api_key, vectordb = init_rag(index_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectordb.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 3})\n",
    "retrieved_docs = retriever.get_relevant_documents(\n",
    "    \"How do I answer: This lead doesnt have a score?\"\n",
    ")\n",
    "len(retrieved_docs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(retrieved_docs)):\n",
    "    print(retrieved_docs[i])\n",
    "    print(retrieved_docs[i].metadata['source'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# initialize the LLM\n",
    "llm = ChatOpenAI(\n",
    "        openai_api_key=openai_api_key,\n",
    "        model_name='gpt-3.5-turbo',\n",
    "        temperature=0.0\n",
    "    )\n",
    "\n",
    "template = \"\"\"Use the following pieces of context to answer the question at the end.\n",
    "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "Use three sentences maximum and keep the answer as concise as possible.\n",
    "Always say \"thanks for asking!\" at the end of the answer.\n",
    "Question: {question}\n",
    "Helpful Answer:\"\"\"\n",
    "rag_prompt_custom = PromptTemplate.from_template(template)\n",
    "\n",
    "\n",
    "# create the function that retrieves source information from the retriever\n",
    "def query_llm_with_source(retriever, query):\n",
    "    qa_chain = RetrievalQAWithSourcesChain.from_chain_type(\n",
    "        llm=llm,\n",
    "        chain_type=\"stuff\",\n",
    "        retriever=retriever\n",
    "    )\n",
    "    results = qa_chain({\n",
    "            'question': query\n",
    "            # ,'rag_prompt_custom': rag_prompt_custom\n",
    "                        })\n",
    "    print(str(results))\n",
    "    return results\n",
    "\n",
    "retriever = vectordb.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 6})\n",
    "\n",
    "query = \"How do I answer: This lead doesnt have a score?\"\n",
    "results = query_llm_with_source(retriever, query)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results['answer'])\n",
    "print(results['sources'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a function to format the sources as a link\n",
    "# we will get the id from the metadata of the retrieved document as described in the example below:\n",
    "# if sources = \"notion_data/support_runbook/Support runbooks d2a894351f944fc5b4abb9f29f30b4a4/User cannot deploy model from the Studio dd2630484a334e159dd9bf07086824ad.md\" then the id is dd2630484a334e159dd9bf07086824ad\n",
    "prefix = 'https://www.notion.so/madkudu/'\n",
    "\n",
    "def format_sources(sources):\n",
    "    formatted_sources = []\n",
    "    source_id = sources.split('/')[-1].split('.')[0].replace(' ','-')\n",
    "    formatted_sources.append(prefix + source_id)\n",
    "    return formatted_sources\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(format_sources(results['sources']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
